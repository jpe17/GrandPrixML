{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Race Prediction\n",
    "#### **Project**: Predicting the results of F1 races based on historical data\n",
    "#### **Context**: The growing F1 industry gets more competitive every year, with performance being more calculated than ever. Would it be possible to predict the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction/Business Problem\n",
    "\n",
    "F1 prediction - does engine play a major impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\joaoe\\\\Documentos\\\\JP\\\\JP_GitHub\\\\f1_predict_ML\\\\f1db_csv\\\\circuits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-65087c23122e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcircuits_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\circuits.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mconstructor_results_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\constructor_results.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mconstructor_standings_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\constructor_standings.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\joaoe\\\\Documentos\\\\JP\\\\JP_GitHub\\\\f1_predict_ML\\\\f1db_csv\\\\circuits.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "circuits_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\circuits.csv')\n",
    "constructor_results_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\constructor_results.csv')\n",
    "constructor_standings_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\constructor_standings.csv')\n",
    "constructors_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\constructors.csv')\n",
    "driver_standigs_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\driver_standings.csv')\n",
    "drivers_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\drivers.csv')\n",
    "lap_times_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\lap_times.csv')\n",
    "pit_stops_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\pit_stops.csv')\n",
    "qualifying_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\qualifying.csv')\n",
    "races_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\races.csv')\n",
    "results_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\results.csv')\n",
    "seasons_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\seasons.csv')\n",
    "status_df = pd.read_csv(r'C:\\Users\\joaoe\\Documentos\\JP\\JP_GitHub\\f1_predict_ML\\f1db_csv\\status.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging races and circuits tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a circuit reference to each corresponding circuit Id\n",
    "circuits_dict = circuits_df.set_index('circuitId')['circuitRef'].to_dict()\n",
    "circuits_in_races = races_df.filter(like='circuitId')\n",
    "races_df['Circuit Reference'] = circuits_in_races.replace(circuits_dict)\n",
    "\n",
    "# Adding a circuit location to each corresponding circuit Id\n",
    "circuits_dict = circuits_df.set_index('circuitId')['location'].to_dict()\n",
    "circuits_in_races = races_df.filter(like='circuitId')\n",
    "races_df['Location'] = circuits_in_races.replace(circuits_dict)\n",
    "\n",
    "# Adding a circuit country to each corresponding circuit Id\n",
    "circuits_dict = circuits_df.set_index('circuitId')['country'].to_dict()\n",
    "circuits_in_races = races_df.filter(like='circuitId')\n",
    "races_df['Country'] = circuits_in_races.replace(circuits_dict)\n",
    "\n",
    "# Adding a circuit latitude to each corresponding circuit Id\n",
    "circuits_dict = circuits_df.set_index('circuitId')['lat'].to_dict()\n",
    "circuits_in_races = races_df.filter(like='circuitId')\n",
    "races_df['Latitude'] = circuits_in_races.replace(circuits_dict)\n",
    "\n",
    "# Adding a circuit longitude to each corresponding circuit Id\n",
    "circuits_dict = circuits_df.set_index('circuitId')['lng'].to_dict()\n",
    "circuits_in_races = races_df.filter(like='circuitId')\n",
    "races_df['Longitude'] = circuits_in_races.replace(circuits_dict)\n",
    "\n",
    "\n",
    "# Droping irrelevant columns\n",
    "races_df = races_df.drop(columns=['raceId','time','circuitId'])\n",
    "\n",
    "races_df = races_df[['year', 'date', 'round', 'name', 'Circuit Reference', 'Location', 'Country', 'Latitude','Longitude']]\n",
    "races_df.rename(columns={'round': 'Round','year': 'Year', 'name': 'Name', 'date': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "weather = races_df.iloc[:,[0,1,2]]\n",
    "\n",
    "info = []\n",
    "\n",
    "# read wikipedia tables\n",
    "\n",
    "for link in races.url:\n",
    "    try:\n",
    "        df = pd.read_html(link)[0]\n",
    "        if 'Weather' in list(df.iloc[:,0]):\n",
    "            n = list(df.iloc[:,0]).index('Weather')\n",
    "            info.append(df.iloc[n,1])\n",
    "        else:\n",
    "            df = pd.read_html(link)[1]\n",
    "            if 'Weather' in list(df.iloc[:,0]):\n",
    "                n = list(df.iloc[:,0]).index('Weather')\n",
    "                info.append(df.iloc[n,1])\n",
    "            else:\n",
    "                df = pd.read_html(link)[2]\n",
    "                if 'Weather' in list(df.iloc[:,0]):\n",
    "                    n = list(df.iloc[:,0]).index('Weather')\n",
    "                    info.append(df.iloc[n,1])\n",
    "                else:\n",
    "                    df = pd.read_html(link)[3]\n",
    "                    if 'Weather' in list(df.iloc[:,0]):\n",
    "                        n = list(df.iloc[:,0]).index('Weather')\n",
    "                        info.append(df.iloc[n,1])\n",
    "                    else:\n",
    "                        driver = webdriver.Chrome()\n",
    "                        driver.get(link)\n",
    "\n",
    "                        # click language button\n",
    "                        button = driver.find_element_by_link_text('Italiano')\n",
    "                        button.click()\n",
    "                        \n",
    "                        # find weather in italian with selenium\n",
    "                        \n",
    "                        clima = driver.find_element_by_xpath('//*[@id=\"mw-content-text\"]/div/table[1]/tbody/tr[9]/td').text\n",
    "                        info.append(clima) \n",
    "                                \n",
    "    except:\n",
    "        info.append('not found')\n",
    "\n",
    "# append column with weather information to dataframe  \n",
    "  \n",
    "weather['weather'] = info\n",
    "\n",
    "# set up a dictionary to convert weather information into keywords\n",
    "\n",
    "weather_dict = {'weather_warm': ['soleggiato', 'clear', 'warm', 'hot', 'sunny', 'fine', 'mild', 'sereno'],\n",
    "               'weather_cold': ['cold', 'fresh', 'chilly', 'cool'],\n",
    "               'weather_dry': ['dry', 'asciutto'],\n",
    "               'weather_wet': ['showers', 'wet', 'rain', 'pioggia', 'damp', 'thunderstorms', 'rainy'],\n",
    "               'weather_cloudy': ['overcast', 'nuvoloso', 'clouds', 'cloudy', 'grey', 'coperto']}\n",
    "\n",
    "# map new df according to weather dictionary\n",
    "\n",
    "weather_df = pd.DataFrame(columns = weather_dict.keys())\n",
    "for col in weather_df:\n",
    "    weather_df[col] = weather['weather'].map(lambda x: 1 if any(i in weather_dict[col] for i in x.lower().split()) else 0)\n",
    "   \n",
    "weather_info = pd.concat([weather, weather_df], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
